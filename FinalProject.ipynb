{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69994617",
   "metadata": {},
   "source": [
    "### Import modules + Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58cba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac710530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "Device: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU available: {}\".format(torch.cuda.is_available()))\n",
    "print(\"Device: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1742fc5",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isotropic_diffusion(img, niter=1, kappa=50, gamma=0.1, voxelspacing=None):\n",
    "\n",
    "    # initialize output array\n",
    "    out = np.array(img, dtype=np.float32, copy=True)\n",
    "\n",
    "    # set default voxel spacing if not supplied\n",
    "    if voxelspacing is None:\n",
    "        voxelspacing = tuple([1.] * img.ndim)\n",
    "\n",
    "    # initialize some internal variables\n",
    "    deltas = [np.zeros_like(out) for _ in range(out.ndim)]\n",
    "\n",
    "    \n",
    "    time = 0\n",
    "    \n",
    "    results_pixels = []\n",
    "    results_dIdt = []\n",
    "    results_time = []\n",
    "    \n",
    "    results_pixels.append(out.astype(img.dtype))\n",
    "    results_time.append(time)\n",
    "    #results_dIdt.append(np.zeros_like(out))\n",
    "\n",
    "    for iter in tqdm(range(niter)):\n",
    "        # calculate the diffs\n",
    "        for i in range(out.ndim):\n",
    "            slicer = [slice(None, -1) if j == i else slice(None) for j in range(out.ndim)]\n",
    "            diff_local = np.diff(out, axis=i)\n",
    "            deltas[i][tuple(slicer)] = diff_local\n",
    "\n",
    "        matrices = [delta for delta, spacing in zip(deltas, voxelspacing)]\n",
    "\n",
    "        # second derivative\n",
    "        for i in range(out.ndim):\n",
    "            slicer = [slice(1, None) if j == i else slice(None) for j in range(out.ndim)]\n",
    "            matrices[i][tuple(slicer)] = np.diff(matrices[i], axis=i)\n",
    "\n",
    "        \n",
    "        dIdt = np.sum(matrices, axis=0)\n",
    "        #print(dIdt)\n",
    "        \n",
    "        # update the image\n",
    "        out += gamma * (dIdt)\n",
    "        time += gamma\n",
    "        \n",
    "        results_dIdt.append(dIdt.astype(img.dtype))\n",
    "        if iter < niter - 1:\n",
    "            results_pixels.append(out.astype(img.dtype))\n",
    "            results_time.append(time)\n",
    "\n",
    "    return results_pixels, results_dIdt, results_time\n",
    "\n",
    "def get_mgrid(sidelen=256, dim=2):\n",
    "    \n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    \n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    \n",
    "    return mgrid\n",
    "\n",
    "class ImageFitting(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, niter):\n",
    "        \n",
    "        self.transform = Compose([\n",
    "            Resize(256),\n",
    "            ToTensor(),\n",
    "            Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "        ])\n",
    "        self.coords = get_mgrid()\n",
    "        \n",
    "        print(\"-----Generating Data-----\")\n",
    "        self.base_img = io.imread(img_path)\n",
    "        self.imgs_pixels, self.imgs_dIdt, self.imgs_time = isotropic_diffusion(self.base_img, niter=niter, kappa=50, gamma=1/(niter+1))\n",
    "\n",
    "        print(\"-----Finished-----\")\n",
    "        \n",
    "        self.len = len(self.imgs_pixels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = self.imgs_pixels[idx]\n",
    "        image = self.transform(Image.fromarray(image))\n",
    "        \n",
    "        pixels = image.permute(1, 2, 0).view(-1, 1)\n",
    "        step_val = torch.full((self.coords.size(0),1), self.imgs_time[idx])\n",
    "\n",
    "        model_input = torch.cat((self.coords, step_val), 1)\n",
    "        \n",
    "        # Compute gradient and laplacian       \n",
    "        grads_x = scipy.ndimage.sobel(image.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y = scipy.ndimage.sobel(image.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "                \n",
    "        grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        laplace = scipy.ndimage.laplace(image.numpy()).squeeze(0)[..., None]\n",
    "        laplace = torch.from_numpy(laplace).view(-1, 1)\n",
    "        \n",
    "        dIdt = torch.from_numpy(self.imgs_dIdt[idx])\n",
    "        dIdt = dIdt.permute(0,1).view(-1)\n",
    "        \n",
    "        return model_input, {'pixels':pixels, 'grads':grads, 'laplace':laplace, 'dIdt':dIdt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98455086",
   "metadata": {},
   "source": [
    "### Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeJacobianFull(x, outputs, create_graph):\n",
    "    \n",
    "    dy_dx = torch.autograd.grad(outputs=outputs, inputs=x, grad_outputs=torch.ones_like(outputs),\n",
    "            retain_graph=True, create_graph=create_graph, allow_unused=True)[0]\n",
    "    \n",
    "    dy_dx = dy_dx.view(outputs.size(0), outputs.size(1), dy_dx.size(2))\n",
    "    \n",
    "    return dy_dx\n",
    "\n",
    "def computeLaplaceFull(x, jacobian, create_graph):\n",
    "    \n",
    "    div = 0\n",
    "    for j in range(jacobian.size(-1)):\n",
    "\n",
    "        dy_dx2 = torch.autograd.grad(outputs=jacobian[:, :, j], inputs=x, grad_outputs=torch.ones_like(jacobian[:, :, j]),\n",
    "            retain_graph=True, create_graph=create_graph)[0][..., j:j+1]\n",
    "\n",
    "        div += dy_dx2\n",
    "\n",
    "    return div\n",
    "\n",
    "def calcLoss(coords, model_output, gt):\n",
    "    \n",
    "    pixel_loss = ((model_output - gt['pixels'])**2).mean()\n",
    "    \n",
    "    gradients = computeJacobianFull(coords, model_output, create_graph=True)\n",
    "    grad_loss = ((gradients[:,:,:-1] - gt['grads']).pow(2).sum(-1)).mean()\n",
    "    \n",
    "    laplacian = computeLaplaceFull(coords, gradients[:,:,:-1], create_graph=False)\n",
    "    laplacian_loss = ((laplacian - gt['laplace'])**2).mean()\n",
    "    \n",
    "    dIdt_loss = ((gradients[:,:,-1] - gt['dIdt'])**2).mean()\n",
    "    \n",
    "    return pixel_loss, grad_loss, laplacian_loss, dIdt_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df674a",
   "metadata": {},
   "source": [
    "### SIREN Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85821428",
   "metadata": {},
   "source": [
    "### ELU Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49abe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELULayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            nn.init.xavier_uniform_(self.linear.weight)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return F.elu(self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.linear(input)\n",
    "        return F.elu(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Base(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(ELULayer(in_features, hidden_features))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(ELULayer(hidden_features, hidden_features))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                nn.init.xavier_uniform_(final_linear.weight)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(ELULayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d55a97",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, writer, img_path, niter, total_epochs=50, beta_0=1, beta_1=1, beta_2=1, beta_3=1, cyclic=False):\n",
    "    \n",
    "    \"\"\"Args:\n",
    "        net: Network to Train\n",
    "        writer: SummaryWriter for logging\n",
    "        img_path: path to default state image\n",
    "        niter: number of steps to apply diffusion (0 means only 1 image)\n",
    "        total_epochs: number of epochs to train\n",
    "        beta_0: constant for loss on pixel value\n",
    "        beta_1: constant for loss on gradients\n",
    "        beta_2: constant for loss on laplacian\n",
    "        beta_3: constant for loss on pixel time derivative\n",
    "        cyclic: CyclicLearning rate (allows better learning)\"\"\"\n",
    "    \n",
    "    \n",
    "    image = ImageFitting(img_path=img_path, niter=niter)\n",
    "    dataloader = DataLoader(image, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "    net.cuda()\n",
    "\n",
    "    epochs_til_summary = 5 #UPDATE ACCORDINGLY\n",
    "    steps_til_summary = 1 #UPDATE ACCORDINGLY\n",
    "\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=net.parameters())\n",
    "    \n",
    "    if cyclic:\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optim, base_lr=1e-7, max_lr=1e-4, step_size_up=250, cycle_momentum=False)\n",
    "    \n",
    "    print(\"-----Begin Training-----\")\n",
    "    for epoch in range(1, total_epochs + 1):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_pixel_loss = 0.0\n",
    "        epoch_grad_loss = 0.0\n",
    "        epoch_laplacian_loss = 0.0\n",
    "        epoch_dIdt_loss = 0.0\n",
    "\n",
    "        for step, batch in tqdm(enumerate(dataloader)):\n",
    "\n",
    "            model_input = batch[0].cuda()\n",
    "            gt = {key: value.cuda() for key, value in batch[1].items()}\n",
    "\n",
    "            model_output, coords = net(model_input)   \n",
    "            \n",
    "            pixel_loss, grad_loss, laplacian_loss, dIdt_loss = calcLoss(coords, model_output, gt)\n",
    "            \n",
    "            loss = beta_0 * pixel_loss + beta_1 * grad_loss + beta_2 * laplacian_loss + beta_3 * dIdt_loss\n",
    "            \n",
    "            epoch_loss += model_output.shape[0] * loss.item()\n",
    "            epoch_pixel_loss += model_output.shape[0] * pixel_loss.item()\n",
    "            epoch_grad_loss += model_output.shape[0] * grad_loss.item()\n",
    "            epoch_laplacian_loss += model_output.shape[0] * laplacian_loss.item()\n",
    "            epoch_dIdt_loss += model_output.shape[0] * dIdt_loss.item()\n",
    "\n",
    "            if not epoch % epochs_til_summary and step % steps_til_summary == steps_til_summary - 1:\n",
    "\n",
    "                pixel_output = model_output[0].view(1, -1, 256, 256)\n",
    "                pixel_gt = gt['pixels'][0].view(1, -1, 256, 256)\n",
    "                img_grid_pixel = torchvision.utils.make_grid(torch.cat((pixel_gt, pixel_output), 0), 2)\n",
    "                img_grid_pixel = img_grid_pixel * 0.5 + 0.5\n",
    "                writer.add_image('pixels', img_grid_pixel, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                \n",
    "                img_grad = computeJacobianFull(coords, model_output, create_graph=True)\n",
    "                grad_output = img_grad[0,:,:-1].norm(dim=-1).view(1, -1, 256, 256)\n",
    "                grad_gt = gt['grads'][0].norm(dim=-1).view(1, -1, 256, 256)\n",
    "                img_grid_grad = torchvision.utils.make_grid(torch.cat((grad_gt, grad_output), 0), 2)\n",
    "                writer.add_image('grads', img_grid_grad, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                \n",
    "                img_laplacian = computeLaplaceFull(coords, img_grad, create_graph=False)\n",
    "                laplacian_output = img_laplacian[0].view(1, -1, 256, 256)\n",
    "                laplacian_gt = gt['laplace'][0].view(1, -1, 256, 256)\n",
    "                img_grid_laplacian = torchvision.utils.make_grid(torch.cat((laplacian_gt, laplacian_output), 0), 2)\n",
    "                writer.add_image('laplacians', img_grid_laplacian, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                dIdt_output = img_grad[0,:,-1].view(1, -1, 256, 256)\n",
    "                dIdt_gt = gt['dIdt'][0].view(1, -1, 256, 256)\n",
    "                img_grid_dIdt = torchvision.utils.make_grid(torch.cat((dIdt_gt, dIdt_output), 0), 2)\n",
    "                writer.add_image('dIdt', img_grid_dIdt, epoch * len(dataloader) + step + 1)\n",
    "\n",
    "                fig, axes = plt.subplots(2,4, figsize=(18,6))\n",
    "                axes[0,0].imshow(gt['pixels'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[0,1].imshow(gt['grads'][0].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "                axes[0,2].imshow(gt['laplace'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[0,3].imshow(gt['dIdt'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,0].imshow(model_output[0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,1].imshow(img_grad[0][:,:-1].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "                axes[1,2].imshow(img_laplacian[0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,3].imshow(img_grad[0][:,-1].cpu().view(256,256).detach().numpy())\n",
    "                plt.show()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            if cyclic:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # logging epoch loss\n",
    "        writer.add_scalar('epoch_loss/total', epoch_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/pixel', epoch_pixel_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/grad', epoch_grad_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/laplacian', epoch_laplacian_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/dIdt', epoch_dIdt_loss/len(image), epoch)\n",
    "        print(\"epoch %d, Epoch loss: total %0.6f, pixel %0.6f, grad %0.6f, laplacian %0.6f, dIdt %0.6f\" % (epoch, epoch_loss/len(image), epoch_pixel_loss/len(image), epoch_grad_loss/len(image), epoch_laplacian_loss/len(image), epoch_dIdt_loss/len(image)))\n",
    "        \n",
    "    print(\"-----Finished-----\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd22f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/siren/cameraman_experiment_pixels')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=0, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a835f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/siren/cameraman_experiment_grads')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=1000, beta_0=0, beta_1=1, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/siren/cameraman_experiment_laplace')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=1000, beta_0=0, beta_1=0, beta_2=1, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/siren/cameraman_experiment_dIdt')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=1000, beta_0=0, beta_1=0, beta_2=0, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/siren/cameraman_experiment_all')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=1000, beta_0=1, beta_1=.01, beta_2=.001, beta_3=.001, cyclic=True)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/base/cameraman_experiment_pixels')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=0, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/base/cameraman_experiment_grads')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=1, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a49ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/base/cameraman_experiment_laplace')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=1, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/base/cameraman_experiment_dIdt')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=0, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded13507",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/base/cameraman_experiment_all')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=1, beta_2=1, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ceb247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
