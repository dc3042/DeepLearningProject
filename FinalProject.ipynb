{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69994617",
   "metadata": {},
   "source": [
    "### Import modules + Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# for SSIM\n",
    "import math\n",
    "\n",
    "# for beta selection\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac710530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU available: {}\".format(torch.cuda.is_available()))\n",
    "print(\"Device: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1742fc5",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isotropic_diffusion(img, niter=1, kappa=50, gamma=0.1, voxelspacing=None):\n",
    "\n",
    "    # initialize output array\n",
    "    out = np.array(img, dtype=np.float32, copy=True)\n",
    "\n",
    "    # set default voxel spacing if not supplied\n",
    "    if voxelspacing is None:\n",
    "        voxelspacing = tuple([1.] * img.ndim)\n",
    "\n",
    "    # initialize some internal variables\n",
    "    deltas = [np.zeros_like(out) for _ in range(out.ndim)]\n",
    "\n",
    "    \n",
    "    time = 0\n",
    "    \n",
    "    results_pixels = []\n",
    "    results_dIdt = []\n",
    "    results_time = []\n",
    "    \n",
    "    results_pixels.append(out.astype(img.dtype))\n",
    "    results_time.append(time)\n",
    "    #results_dIdt.append(np.zeros_like(out))\n",
    "\n",
    "    for iter in tqdm(range(niter)):\n",
    "        # calculate the diffs\n",
    "        for i in range(out.ndim):\n",
    "            slicer = [slice(None, -1) if j == i else slice(None) for j in range(out.ndim)]\n",
    "            diff_local = np.diff(out, axis=i)\n",
    "            deltas[i][tuple(slicer)] = diff_local\n",
    "\n",
    "        matrices = [delta for delta, spacing in zip(deltas, voxelspacing)]\n",
    "\n",
    "        # second derivative\n",
    "        for i in range(out.ndim):\n",
    "            slicer = [slice(1, None) if j == i else slice(None) for j in range(out.ndim)]\n",
    "            matrices[i][tuple(slicer)] = np.diff(matrices[i], axis=i)\n",
    "\n",
    "        \n",
    "        dIdt = np.sum(matrices, axis=0)\n",
    "        #print(dIdt)\n",
    "        \n",
    "        # update the image\n",
    "        out += gamma * (dIdt)\n",
    "        time += gamma\n",
    "        \n",
    "        results_dIdt.append(dIdt.astype(img.dtype))\n",
    "        if iter < niter - 1:\n",
    "            results_pixels.append(out.astype(img.dtype))\n",
    "            results_time.append(time)\n",
    "\n",
    "    return results_pixels, results_dIdt, results_time\n",
    "\n",
    "def get_mgrid(sidelen=256, dim=2):\n",
    "    \n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    \n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    \n",
    "    return mgrid\n",
    "\n",
    "class ImageFitting(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, niter):\n",
    "        \n",
    "        self.transform = Compose([\n",
    "            Resize(256),\n",
    "            ToTensor(),\n",
    "            Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "        ])\n",
    "        self.coords = get_mgrid()\n",
    "        \n",
    "        print(\"-----Generating Data-----\")\n",
    "        self.base_img = io.imread(img_path)\n",
    "        self.imgs_pixels, self.imgs_dIdt, self.imgs_time = isotropic_diffusion(self.base_img, niter=niter, kappa=50, gamma=1/(niter+1))\n",
    "\n",
    "        print(\"-----Finished-----\")\n",
    "        \n",
    "        self.len = len(self.imgs_pixels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = self.imgs_pixels[idx]\n",
    "        image = self.transform(Image.fromarray(image))\n",
    "        \n",
    "        pixels = image.permute(1, 2, 0).view(-1, 1)\n",
    "        step_val = torch.full((self.coords.size(0),1), self.imgs_time[idx])\n",
    "\n",
    "        model_input = torch.cat((self.coords, step_val), 1)\n",
    "        \n",
    "        # Compute gradient and laplacian       \n",
    "        grads_x = scipy.ndimage.sobel(image.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y = scipy.ndimage.sobel(image.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "                \n",
    "        grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        laplace = scipy.ndimage.laplace(image.numpy()).squeeze(0)[..., None]\n",
    "        laplace = torch.from_numpy(laplace).view(-1, 1)\n",
    "        \n",
    "        dIdt = torch.from_numpy(self.imgs_dIdt[idx])\n",
    "        dIdt = dIdt.permute(0,1).view(-1)\n",
    "        \n",
    "        return model_input, {'pixels':pixels, 'grads':grads, 'laplace':laplace, 'dIdt':dIdt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98455086",
   "metadata": {},
   "source": [
    "### Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeJacobianFull(x, outputs, create_graph):\n",
    "    \n",
    "    dy_dx = torch.autograd.grad(outputs=outputs, inputs=x, grad_outputs=torch.ones_like(outputs),\n",
    "            retain_graph=True, create_graph=create_graph, allow_unused=True)[0]\n",
    "    \n",
    "    dy_dx = dy_dx.view(outputs.size(0), outputs.size(1), dy_dx.size(2))\n",
    "    \n",
    "    return dy_dx\n",
    "\n",
    "def computeLaplaceFull(x, jacobian, create_graph):\n",
    "    \n",
    "    div = 0\n",
    "    for j in range(jacobian.size(-1)):\n",
    "\n",
    "        dy_dx2 = torch.autograd.grad(outputs=jacobian[:, :, j], inputs=x, grad_outputs=torch.ones_like(jacobian[:, :, j]),\n",
    "            retain_graph=True, create_graph=create_graph)[0][..., j:j+1]\n",
    "\n",
    "        div += dy_dx2\n",
    "\n",
    "    return div\n",
    "\n",
    "def calcLoss(coords, model_output, gt):\n",
    "    \n",
    "    pixel_loss = ((model_output - gt['pixels'])**2).mean()\n",
    "    \n",
    "    gradients = computeJacobianFull(coords, model_output, create_graph=True)\n",
    "    grad_loss = ((gradients[:,:,:-1] - gt['grads']).pow(2).sum(-1)).mean()\n",
    "    \n",
    "    laplacian = computeLaplaceFull(coords, gradients[:,:,:-1], create_graph=False)\n",
    "    laplacian_loss = ((laplacian - gt['laplace'])**2).mean()\n",
    "    \n",
    "    dIdt_loss = ((gradients[:,:,-1] - gt['dIdt'])**2).mean()\n",
    "    \n",
    "    pixel_ssim = mean_ssim(gt['pixels'][0].cpu().view(1, 256,256).detach(), model_output[0].cpu().view(1, 256,256).detach(), val_range=255)\n",
    "    \n",
    "    grad_ssim = mean_ssim(gt['grads'][0].norm(dim=-1).cpu().view(1, 256,256).detach(), gradients[0][:,:-1].norm(dim=-1).cpu().view(1, 256,256).detach(), val_range=255)\n",
    "    \n",
    "    laplacian_ssim = mean_ssim(gt['laplace'][0].cpu().view(1, 256,256).detach(), laplacian[0].cpu().view(1, 256,256).detach(), val_range=255)\n",
    "    \n",
    "    dIdt_ssim = mean_ssim(gt['dIdt'][0].cpu().view(1, 256,256).float().detach(), gradients[0][:,-1].cpu().view(1, 256,256).detach(), val_range=255)\n",
    "    \n",
    "    return pixel_loss, grad_loss, laplacian_loss, dIdt_loss, pixel_ssim, grad_ssim, laplacian_ssim, dIdt_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92b77f-82fb-4449-8a66-66fbbd1fe8c4",
   "metadata": {},
   "source": [
    "### SSIM (Structural Similarity Index Measure)\n",
    "original SSIM paper: https://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf \\\n",
    "code source: https://github.com/pranjaldatta/SSIM-PyTorch \\\n",
    "explanation: https://medium.com/srm-mic/all-about-structural-similarity-index-ssim-theory-code-in-pytorch-6551b455541e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c43659-44d0-4e9a-8e2a-80e16f117b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size=11, sigma=1.5):\n",
    "    \"\"\"\n",
    "    Generates a list of Tensor values drawn from a gaussian distribution with standard\n",
    "    diviation = sigma and sum of all elements = 1.\n",
    "\n",
    "    Length of list = window_size\n",
    "    \"\"\"    \n",
    "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df9ba8-916f-45e2-b9e4-feb356a9da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(window_size=11, channel=1):\n",
    "\n",
    "    # Generate an 1D tensor containing values sampled from a gaussian distribution\n",
    "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
    "    \n",
    "    # Converting to 2D  \n",
    "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "     \n",
    "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63627db-be8f-43cc-bf2c-1cfa23a88b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean SSIM with SSIM applied locally over moving windows\n",
    "# output = 1: the same image, output = 0 (or -1): very different\n",
    "def mean_ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n",
    "\n",
    "    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
    "\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    try:\n",
    "        _, channels, height, width = img1.size()\n",
    "    except:\n",
    "        channels, height, width = img1.size()\n",
    "\n",
    "    # if window is not provided, init one\n",
    "    if window is None: \n",
    "        real_size = min(window_size, height, width) # window should be atleast 11x11 \n",
    "        window = create_window(real_size, channel=channels).to(img1.device)\n",
    "    \n",
    "    # calculating the mu parameter (locally) for both images using a gaussian filter \n",
    "    # calculates the luminosity params\n",
    "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2 \n",
    "    mu12 = mu1 * mu2\n",
    "\n",
    "    # now we calculate the sigma square parameter\n",
    "    # Sigma deals with the contrast component \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
    "\n",
    "    # Some constants for stability \n",
    "    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
    "    C2 = (0.03 ) ** 2 \n",
    "\n",
    "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    contrast_metric = torch.mean(contrast_metric)\n",
    "\n",
    "    numerator1 = 2 * mu12 + C1  \n",
    "    numerator2 = 2 * sigma12 + C2\n",
    "    denominator1 = mu1_sq + mu2_sq + C1 \n",
    "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
    "\n",
    "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_score.mean() \n",
    "    else: \n",
    "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
    "    \n",
    "    if full:\n",
    "        return ret, contrast_metric\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365dc37-67c6-4dab-a312-2cf80a49eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to convert to Tensors\n",
    "tensorify = lambda x: torch.Tensor(x.transpose((1, 0))).unsqueeze(0).float().div(255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b93f4-7747-43de-9e2e-e7b548f3b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Example Usage ###\n",
    "\n",
    "# img_path_temp = 'original/cameraman.png'\n",
    "# img1 = io.imread(img_path_temp)\n",
    "# img2 = io.imread(img_path_temp)\n",
    "\n",
    "# # Check SSIM score of True image vs False Image\n",
    "# _img1 = tensorify(img1)\n",
    "# _img2 = tensorify(img2)\n",
    "# true_vs_false = mean_ssim(_img1, _img2, val_range=255)\n",
    "# print(\"True vs False Image SSIM Score:\", true_vs_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df674a",
   "metadata": {},
   "source": [
    "### SIREN Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85821428",
   "metadata": {},
   "source": [
    "### ELU Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49abe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELULayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            nn.init.xavier_uniform_(self.linear.weight)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return F.elu(self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.linear(input)\n",
    "        return F.elu(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Base(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(ELULayer(in_features, hidden_features))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(ELULayer(hidden_features, hidden_features))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                nn.init.xavier_uniform_(final_linear.weight)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(ELULayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d55a97",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, writer, img_path, niter, total_epochs=50, lr=[1e-4], beta_0=1, beta_1=1, beta_2=1, beta_3=1, \n",
    "          cyclic=False, decay_exp=False, decay_multi=False):\n",
    "    \n",
    "    \"\"\"Args:\n",
    "        net: Network to Train\n",
    "        writer: SummaryWriter for logging\n",
    "        img_path: path to default state image\n",
    "        niter: number of steps to apply diffusion (0 means only 1 image)\n",
    "        total_epochs: number of epochs to train\n",
    "        beta_0: constant for loss on pixel value\n",
    "        beta_1: constant for loss on gradients\n",
    "        beta_2: constant for loss on laplacian\n",
    "        beta_3: constant for loss on pixel time derivative\n",
    "        cyclic: CyclicLearning rate (allows better learning)\"\"\"\n",
    "    \n",
    "    \n",
    "    image = ImageFitting(img_path=img_path, niter=niter)\n",
    "    dataloader = DataLoader(image, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "    net.cuda()\n",
    "\n",
    "    epochs_til_summary = 10 #UPDATE ACCORDINGLY\n",
    "    steps_til_summary = 5 #UPDATE ACCORDINGLY\n",
    "\n",
    "    optim = torch.optim.Adam(lr=lr[0], params=net.parameters())\n",
    "    \n",
    "    if decay_multi:\n",
    "        m = np.floor(total_epochs/4)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optim, milestones=[m*1,m*2,m*3], gamma=0.1)\n",
    "    \n",
    "    if decay_exp:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9)\n",
    "    \n",
    "    if cyclic:\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optim, base_lr=lr[1], max_lr=lr[0], step_size_up=250, cycle_momentum=False)\n",
    "    \n",
    "    print(\"-----Begin Training-----\")\n",
    "    for epoch in range(1, total_epochs + 1):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_pixel_loss = 0.0\n",
    "        epoch_grad_loss = 0.0\n",
    "        epoch_laplacian_loss = 0.0\n",
    "        epoch_dIdt_loss = 0.0\n",
    "        \n",
    "        epoch_pixel_ssim = 0.0\n",
    "        epoch_grad_ssim = 0.0\n",
    "        epoch_laplacian_ssim = 0.0\n",
    "        epoch_dIdt_ssim = 0.0\n",
    "\n",
    "        for step, batch in tqdm(enumerate(dataloader)):\n",
    "\n",
    "            model_input = batch[0].cuda()\n",
    "            gt = {key: value.cuda() for key, value in batch[1].items()}\n",
    "\n",
    "            model_output, coords = net(model_input)   \n",
    "            \n",
    "            pixel_loss, grad_loss, laplacian_loss, dIdt_loss, pixel_ssim, grad_ssim, laplacian_ssim, dIdt_ssim = calcLoss(coords, model_output, gt)\n",
    "            \n",
    "            loss = beta_0 * pixel_loss + beta_1 * grad_loss + beta_2 * laplacian_loss + beta_3 * dIdt_loss\n",
    "            \n",
    "            epoch_loss += model_output.shape[0] * loss.item()\n",
    "            epoch_pixel_loss += model_output.shape[0] * pixel_loss.item()\n",
    "            epoch_grad_loss += model_output.shape[0] * grad_loss.item()\n",
    "            epoch_laplacian_loss += model_output.shape[0] * laplacian_loss.item()\n",
    "            epoch_dIdt_loss += model_output.shape[0] * dIdt_loss.item()\n",
    "\n",
    "            epoch_pixel_ssim += model_output.shape[0] * pixel_ssim.item()\n",
    "            epoch_grad_ssim += model_output.shape[0] * grad_ssim.item()\n",
    "            epoch_laplacian_ssim += model_output.shape[0] * laplacian_ssim.item()\n",
    "            epoch_dIdt_ssim += model_output.shape[0] * dIdt_ssim.item()\n",
    "\n",
    "            if not epoch % epochs_til_summary and step % steps_til_summary == steps_til_summary - 1:\n",
    "\n",
    "                pixel_output = model_output[0].view(1, -1, 256, 256)\n",
    "                pixel_gt = gt['pixels'][0].view(1, -1, 256, 256)\n",
    "                img_grid_pixel = torchvision.utils.make_grid(torch.cat((pixel_gt, pixel_output), 0), 2)\n",
    "                img_grid_pixel = img_grid_pixel * 0.5 + 0.5\n",
    "                writer.add_image('pixels', img_grid_pixel, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                \n",
    "                img_grad = computeJacobianFull(coords, model_output, create_graph=True)\n",
    "                grad_output = img_grad[0,:,:-1].norm(dim=-1).view(1, -1, 256, 256)\n",
    "                grad_gt = gt['grads'][0].norm(dim=-1).view(1, -1, 256, 256)\n",
    "                img_grid_grad = torchvision.utils.make_grid(torch.cat((grad_gt, grad_output), 0), 2)\n",
    "                writer.add_image('grads', img_grid_grad, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                \n",
    "                img_laplacian = computeLaplaceFull(coords, img_grad, create_graph=False)\n",
    "                laplacian_output = img_laplacian[0].view(1, -1, 256, 256)\n",
    "                laplacian_gt = gt['laplace'][0].view(1, -1, 256, 256)\n",
    "                img_grid_laplacian = torchvision.utils.make_grid(torch.cat((laplacian_gt, laplacian_output), 0), 2)\n",
    "                writer.add_image('laplacians', img_grid_laplacian, epoch * len(dataloader) + step + 1)\n",
    "                \n",
    "                dIdt_output = img_grad[0,:,-1].view(1, -1, 256, 256)\n",
    "                dIdt_gt = gt['dIdt'][0].view(1, -1, 256, 256)\n",
    "                img_grid_dIdt = torchvision.utils.make_grid(torch.cat((dIdt_gt, dIdt_output), 0), 2)\n",
    "                writer.add_image('dIdt', img_grid_dIdt, epoch * len(dataloader) + step + 1)\n",
    "\n",
    "                fig, axes = plt.subplots(2,4, figsize=(18,6))\n",
    "                axes[0,0].imshow(gt['pixels'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[0,1].imshow(gt['grads'][0].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "                axes[0,2].imshow(gt['laplace'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[0,3].imshow(gt['dIdt'][0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,0].imshow(model_output[0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,1].imshow(img_grad[0][:,:-1].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "                axes[1,2].imshow(img_laplacian[0].cpu().view(256,256).detach().numpy())\n",
    "                axes[1,3].imshow(img_grad[0][:,-1].cpu().view(256,256).detach().numpy())\n",
    "                plt.show()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            if cyclic or decay_exp or decay_multi:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # logging epoch loss\n",
    "        writer.add_scalar('epoch_loss/total', epoch_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/pixel', epoch_pixel_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/grad', epoch_grad_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/laplacian', epoch_laplacian_loss/len(image), epoch)\n",
    "        writer.add_scalar('epoch_loss/dIdt', epoch_dIdt_loss/len(image), epoch)\n",
    "        print(\"epoch %d, Epoch loss: total %0.6f, pixel %0.6f, grad %0.6f, laplacian %0.6f, dIdt %0.6f\" % (epoch, epoch_loss/len(image), epoch_pixel_loss/len(image), epoch_grad_loss/len(image), epoch_laplacian_loss/len(image), epoch_dIdt_loss/len(image)))\n",
    "        \n",
    "        # logging ssim loss\n",
    "        writer.add_scalar('epoch_ssim/pixel', epoch_pixel_ssim/len(image), epoch)\n",
    "        writer.add_scalar('epoch_ssim/grad', epoch_grad_ssim/len(image), epoch)\n",
    "        writer.add_scalar('epoch_ssim/laplacian', epoch_laplacian_ssim/len(image), epoch)\n",
    "        writer.add_scalar('epoch_ssim/dIdt', epoch_dIdt_ssim/len(image), epoch)\n",
    "        print(\"Epoch SSIM: pixel %0.6f, grad %0.6f, laplacian %0.6f, dIdt %0.6f\" % (epoch, epoch_pixel_ssim/len(image), epoch_grad_ssim/len(image), epoch_laplacian_ssim/len(image), epoch_dIdt_ssim/len(image)))\n",
    "    \n",
    "    writer.add_graph(net, model_input)\n",
    "    print(\"-----Finished-----\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605357e-b2c5-4d80-b6eb-903581870ae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6eb16-6979-44dd-9dd8-67af13203c80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### SIREN Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd22f49",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIREN, learn only with the observed pixel values\n",
    "writer = SummaryWriter('runs/siren/cameraman_experiment_pixels')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=10, total_epochs=10, beta_0=1, beta_1=0, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a835f31",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIREN, learn only with the observed jacobians (first derivative in space)\n",
    "writer = SummaryWriter('runs/siren/cameraman_experiment_grads')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=1, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7e23a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIREN, learns only with the observed laplacians (2nd derivative in space)\n",
    "writer = SummaryWriter('runs/siren/cameraman_experiment_laplace')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=1, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e1ff7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIREN, learn only with the observed derivative in time (3rd derivative)\n",
    "writer = SummaryWriter('runs/siren/cameraman_experiment_dIdt')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=0, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291d15c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIREN, learn with all data, equally weighted\n",
    "writer = SummaryWriter('runs/siren/cameraman_experiment_all')\n",
    "\n",
    "img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_siren, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=1, beta_2=1, beta_3=1, cyclic=True)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d68bc-bb7c-4812-8db0-7bf07fe6620b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Elu Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3bf1d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base, learn only with the observed pixel values\n",
    "writer = SummaryWriter('runs/base/cameraman_experiment_pixels')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=0, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07a7c2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base, learn only with the observed jacobians (first derivative in space)\n",
    "writer = SummaryWriter('runs/base/cameraman_experiment_grads')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=1, beta_2=0, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a49ed4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base, learn only with the observed laplacians (2nd derivative in space)\n",
    "writer = SummaryWriter('runs/base/cameraman_experiment_laplace')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=1, beta_3=0)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af1b81",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base, learn only with the observed derivative in time (3rd derivative)\n",
    "writer = SummaryWriter('runs/base/cameraman_experiment_dIdt')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=0, beta_1=0, beta_2=0, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded13507",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base, learn with all data, equally weighted\n",
    "writer = SummaryWriter('runs/base/cameraman_experiment_all')\n",
    "\n",
    "img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "train(img_base, writer, img_path='original/cameraman.png', niter=1, total_epochs=10, beta_0=1, beta_1=1, beta_2=1, beta_3=1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db309f8a-bd3e-4b60-b07b-398b87ba5e56",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d75b75-e1e1-43b4-80fb-68703a779d0c",
   "metadata": {},
   "source": [
    "#### Experiments Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c1747-f370-4369-b113-b70bcf7be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @min_beta_sum: minimum sum of all four beta values\n",
    "# @return: a list of 4 beta values, summing to at least min_beta_sum\n",
    "def generate_random_beta_combos(min_beta_sum=0.3):\n",
    "    possible_values = [1.0, 0.1, 0.01, 0.001, 0.0]\n",
    "    betas = [0, 0, 0, 0]\n",
    "    \n",
    "    while np.sum(betas) <= min_beta_sum:\n",
    "        betas = [random.choice(possible_values) for i in range(4)]\n",
    "        \n",
    "    return betas\n",
    "\n",
    "# @betas: a list of beta values\n",
    "# @return: a string with '_' between all beta values\n",
    "def b_to_string(betas):\n",
    "    return '_'.join(map(str, betas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8841bb-cd9d-418f-8750-1e9a4d6c05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs one experiment with the elu activation function\n",
    "def run_elu(model_path, betas, total_epochs, lr, cyclic=False, decay_exp=False, decay_multi=False):\n",
    "    writer = SummaryWriter(model_path)\n",
    "    \n",
    "    img_base = Base(in_features=3, out_features=1, hidden_features=512, \n",
    "                    hidden_layers=3, outermost_linear=True)\n",
    "    \n",
    "    train(img_base, writer, img_path='original/cameraman.png', niter=10, \n",
    "          total_epochs=total_epochs, lr=lr,\n",
    "          beta_0=betas[0], beta_1=betas[1], beta_2=betas[2], beta_3=betas[3], \n",
    "          cyclic=cyclic, decay_exp=decay_exp, decay_multi=decay_multi)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30343757-e34c-494b-8487-f7c30af035f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs one experiment with the SIREN (periodic) activation function\n",
    "def run_siren(model_path, betas, total_epochs, lr, cyclic=False, decay_exp=False, decay_multi=False):\n",
    "    writer = SummaryWriter(model_path)\n",
    "    \n",
    "    img_siren = Siren(in_features=3, out_features=1, hidden_features=512, \n",
    "                      hidden_layers=3, outermost_linear=True)\n",
    "    \n",
    "    train(img_siren, writer, img_path='original/cameraman.png', niter=10, \n",
    "          total_epochs=total_epochs, lr=lr,\n",
    "          beta_0=betas[0], beta_1=betas[1], beta_2=betas[2], beta_3=betas[3], \n",
    "          cyclic=cyclic, decay_exp=decay_exp, decay_multi=decay_multi)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9988b37-313e-47a2-87cc-56638118ce00",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533f505-ac44-4c22-b4ca-3c758b130951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "model_path = 'runs/base/cameraman'\n",
    "total_epochs = 10\n",
    "learning_rates = [1e-4, 1e-5, 1e-6, 1e-7]\n",
    "\n",
    "# keep conducting experiments until we've reached the desired amount\n",
    "num_experiments = 0\n",
    "while num_experiments < 1:\n",
    "    \n",
    "    # get a random combination of betas\n",
    "    betas = generate_random_beta_combos()\n",
    "    model_path += \"/\" + b_to_string(betas)\n",
    "    \n",
    "    ### Part A. Models with elu activation ###\n",
    "    model_path_act = model_path + '/elu_'\n",
    "    \n",
    "    ## learning rate experiments ##\n",
    "    \n",
    "    # 1. run with uniform learning rates\n",
    "    for uniform_lr in learning_rates:\n",
    "        model_path_full = model_path_act + 'uniformlr_' + \"{:.0e}\".format(uniform_lr)\n",
    "        run_elu(model_path_full, betas, total_epochs, [uniform_lr])\n",
    "    \n",
    "    # 2. run with decaying learning rates\n",
    "    initial_lr = learning_rates[0]\n",
    "    \n",
    "    # 2.1 multi-step: decay_multi = True\n",
    "    model_path_full = model_path_act + '_decay_multi_' + \"{:.0e}\".format(initial_lr)\n",
    "    run_elu(model_path_full, betas, total_epochs, [initial_lr], decay_multi=True)\n",
    "    \n",
    "    # 2.2 exponential: decay_exp = True\n",
    "    model_path_full = model_path_act + '_decay_exp_' + \"{:.0e}\".format(initial_lr)\n",
    "    run_elu(model_path_full, betas, total_epochs, [initial_lr], decay_exp=True)\n",
    "    \n",
    "    # 3. run with cyclic learning rate\n",
    "    max_lr = learning_rates[0]\n",
    "    min_lr = learning_rates[-1]\n",
    "    model_path_full = model_path_act + '_cyclic_' + \"{:.0e}\".format(max_lr) + \"_\" + \"{:.0e}\".format(min_lr)\n",
    "    run_elu(model_path_full, betas, total_epochs, [max_lr, min_lr], cyclic=True)\n",
    "    \n",
    "    \n",
    "    ### Part B. Models with SIREN (periodic) activation ###\n",
    "    model_path_act = model_path + '/siren_'\n",
    "    \n",
    "    ## learning rate experiments ##\n",
    "    \n",
    "    # 1. run with uniform learning rates\n",
    "    for uniform_lr in learning_rates:\n",
    "        model_path_full = model_path_act + 'uniformlr_' + \"{:.0e}\".format(uniform_lr)\n",
    "        run_siren(model_path_full, betas, total_epochs, [uniform_lr])\n",
    "    \n",
    "    # 2. run with decaying learning rates\n",
    "    initial_lr = learning_rates[0]\n",
    "    \n",
    "    # 2.1 multi-step: decay_multi = True\n",
    "    model_path_full = model_path_act + '_decay_multi_' + \"{:.0e}\".format(initial_lr)\n",
    "    run_siren(model_path_full, betas, total_epochs, [initial_lr], decay_multi=True)\n",
    "    \n",
    "    # 2.2 exponential: decay_exp = True\n",
    "    model_path_full = model_path_act + '_decay_exp_' + \"{:.0e}\".format(initial_lr)\n",
    "    run_siren(model_path_full, betas, total_epochs, [initial_lr], decay_exp=True)\n",
    "    \n",
    "    # 3. run with cyclic learning rate\n",
    "    max_lr = learning_rates[0]\n",
    "    min_lr = learning_rates[-1]\n",
    "    model_path_full = model_path_act + '_cyclic_' + \"{:.0e}\".format(max_lr) + \"_\" + \"{:.0e}\".format(min_lr)\n",
    "    run_siren(model_path_full, betas, total_epochs, [max_lr, min_lr], cyclic=True)\n",
    "    \n",
    "    \n",
    "    # finished one more experiment\n",
    "    num_experiments += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030d1de-5dba-4d41-927d-3ea0b68c3353",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ceb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def output_video(net, img_path, niter, vidName='video_name.mp4'):\n",
    "\n",
    "    image = ImageFitting(img_path=img_path, niter=niter)\n",
    "    dataloader = DataLoader(image, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "    net.cuda()\n",
    "    \n",
    "    if os.path.exists(\"tmp\"):\n",
    "        shutil.rmtree(\"tmp\")\n",
    "    os.makedirs(\"tmp\")\n",
    "\n",
    "    for step, batch in tqdm(enumerate(dataloader)):\n",
    "        \n",
    "        model_input = batch[0].cuda()\n",
    "        gt = {key: value.cuda() for key, value in batch[1].items()}\n",
    "\n",
    "        model_output, coords = net(model_input)\n",
    "        img_grad = computeJacobianFull(coords, model_output, create_graph=True)\n",
    "        img_laplacian = computeLaplaceFull(coords, img_grad, create_graph=False)\n",
    "\n",
    "        fig, axes = plt.subplots(2,4, figsize=(18,6))\n",
    "        axes[0,0].imshow(gt['pixels'][0].cpu().view(256,256).detach().numpy())\n",
    "        axes[0,1].imshow(gt['grads'][0].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "        axes[0,2].imshow(gt['laplace'][0].cpu().view(256,256).detach().numpy())\n",
    "        axes[0,3].imshow(gt['dIdt'][0].cpu().view(256,256).detach().numpy())\n",
    "        axes[1,0].imshow(model_output[0].cpu().view(256,256).detach().numpy())\n",
    "        axes[1,1].imshow(img_grad[0][:,:-1].norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "        axes[1,2].imshow(img_laplacian[0].cpu().view(256,256).detach().numpy())\n",
    "        axes[1,3].imshow(img_grad[0][:,-1].cpu().view(256,256).detach().numpy())\n",
    "        \n",
    "        fig.savefig(\"tmp/file%02d.png\" % step)\n",
    "\n",
    "    \n",
    "    subprocess.call([\n",
    "        'ffmpeg', '-framerate', '2', '-i', 'tmp/file%02d.png', '-r', '30', '-pix_fmt', 'yuv420p',\n",
    "        vidName\n",
    "    ])\n",
    "    \n",
    "    shutil.rmtree(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video(img_siren, img_path='original/cameraman.png', niter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b61e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
